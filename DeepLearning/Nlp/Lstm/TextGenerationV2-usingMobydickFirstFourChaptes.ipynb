{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b4e013",
   "metadata": {},
   "source": [
    "### Here I use the Lstm model to can predict the next sequence of words when it takes sequence of words as input \n",
    "### This notebook is trained on the first 4 chapters of the mobydick book then use them to can predict any sequence of words you need ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3afc56",
   "metadata": {},
   "source": [
    "### Method to can read any file as one string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "122832b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:19.081595Z",
     "start_time": "2022-06-27T14:37:19.068630Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path) as f:\n",
    "        string=f.read()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b55c4b",
   "metadata": {},
   "source": [
    "### Read the first four chapters of moby dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0338093f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:03.095466Z",
     "start_time": "2022-06-27T14:01:02.898705Z"
    }
   },
   "outputs": [],
   "source": [
    "doc=read_file('moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a3c64",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9421db35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T15:06:45.133770Z",
     "start_time": "2022-06-27T15:06:45.115818Z"
    }
   },
   "source": [
    "### Import spacy and tokenizer to can handel the text cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cc582016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:00:55.324957Z",
     "start_time": "2022-06-27T14:00:46.441905Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "nlp=spacy.load(\"en_core_web_lg\")\n",
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51766b28",
   "metadata": {},
   "source": [
    "### This method to reomve any special char can found in the text to can only works on the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2f45120c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:06.138482Z",
     "start_time": "2022-06-27T14:01:06.120194Z"
    }
   },
   "outputs": [],
   "source": [
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591dd841",
   "metadata": {},
   "source": [
    "### Run the method on the read document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "68fc8973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:18.033886Z",
     "start_time": "2022-06-27T14:01:14.585835Z"
    }
   },
   "outputs": [],
   "source": [
    "TokensInText=separate_punc(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d031d66",
   "metadata": {},
   "source": [
    "### The counts of the words in document is ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3bc25e24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:25.902903Z",
     "start_time": "2022-06-27T14:01:25.882913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11338"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TokensInText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66d23a8",
   "metadata": {},
   "source": [
    "### Now we need to make a sequence of 26 words to can train the model on \n",
    "### Here we said that the sequence will be 25 words and model labeled data is one word\n",
    "### You can change them if you need just change the varaibles value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b606e05d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:24.491943Z",
     "start_time": "2022-06-27T14:37:24.468005Z"
    }
   },
   "outputs": [],
   "source": [
    "## Now we need to make model to takes 25 words and predict the 26 word so will divid our text\n",
    "length_of_taken_words=25\n",
    "no_of_words_predict=1\n",
    "Sentences=[TokensInText[i-(length_of_taken_words+no_of_words_predict):i] for i in range((length_of_taken_words+no_of_words_predict),len(TokensInText))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf89fa1",
   "metadata": {},
   "source": [
    "### Example of the sentences \n",
    "### Note is is the fully sentence the 25 word plus the one word (lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6e9b0e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:27.013681Z",
     "start_time": "2022-06-27T14:37:27.004706Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long',\n",
       " 'precisely',\n",
       " 'having',\n",
       " 'little',\n",
       " 'or',\n",
       " 'no',\n",
       " 'money',\n",
       " 'in',\n",
       " 'my',\n",
       " 'purse',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'particular',\n",
       " 'to',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'on',\n",
       " 'shore']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b1c776",
   "metadata": {},
   "source": [
    "### you can see the sentence as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "17731a5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:29.089621Z",
     "start_time": "2022-06-27T14:37:29.082640Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(Sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf3107",
   "metadata": {},
   "source": [
    "### How many sentence we have ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c6b97e7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:29.837199Z",
     "start_time": "2022-06-27T14:37:29.818250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11312"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ccdf93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T15:17:36.687969Z",
     "start_time": "2022-06-27T15:17:36.675955Z"
    }
   },
   "source": [
    "# Now PreProcessing the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e353fdf",
   "metadata": {},
   "source": [
    "### How can convert the text to number ??\n",
    "### Keras solve it by easy way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8dba08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T02:12:19.311663Z",
     "start_time": "2022-06-27T02:12:19.294128Z"
    }
   },
   "source": [
    "# Keras and Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b1e887",
   "metadata": {},
   "source": [
    "### We make an object of tokenizer to can takes our sentences and generate tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6ad4e099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:32.947480Z",
     "start_time": "2022-06-27T14:01:32.938479Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ac8921",
   "metadata": {},
   "source": [
    "### Fit our Sentences on  the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4dd01e1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:34.131909Z",
     "start_time": "2022-06-27T14:01:33.944874Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(Sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6985d782",
   "metadata": {},
   "source": [
    "### Now our sentences are generated as number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9764a793",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:35.431725Z",
     "start_time": "2022-06-27T14:01:35.218087Z"
    }
   },
   "outputs": [],
   "source": [
    "NewSentences=tokenizer.texts_to_sequences(Sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b2e3e",
   "metadata": {},
   "source": [
    "### so now we can see our first sentence after converge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b2a0d641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:36.328176Z",
     "start_time": "2022-06-27T14:01:36.323186Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[956,\n",
       " 14,\n",
       " 263,\n",
       " 51,\n",
       " 261,\n",
       " 408,\n",
       " 87,\n",
       " 219,\n",
       " 129,\n",
       " 111,\n",
       " 954,\n",
       " 260,\n",
       " 50,\n",
       " 43,\n",
       " 38,\n",
       " 314,\n",
       " 7,\n",
       " 23,\n",
       " 546,\n",
       " 3,\n",
       " 150,\n",
       " 259,\n",
       " 6,\n",
       " 2713,\n",
       " 14,\n",
       " 24]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewSentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831219b6",
   "metadata": {},
   "source": [
    "### we can see how the token class convert every token to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "94a742c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:38.400597Z",
     "start_time": "2022-06-27T14:01:38.267976Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'the',\n",
       " 2: 'a',\n",
       " 3: 'and',\n",
       " 4: 'of',\n",
       " 5: 'i',\n",
       " 6: 'to',\n",
       " 7: 'in',\n",
       " 8: 'it',\n",
       " 9: 'that',\n",
       " 10: 'he',\n",
       " 11: 'his',\n",
       " 12: 'was',\n",
       " 13: 'but',\n",
       " 14: 'me',\n",
       " 15: 'with',\n",
       " 16: 'as',\n",
       " 17: 'at',\n",
       " 18: 'this',\n",
       " 19: 'you',\n",
       " 20: 'is',\n",
       " 21: 'all',\n",
       " 22: 'for',\n",
       " 23: 'my',\n",
       " 24: 'on',\n",
       " 25: 'be',\n",
       " 26: \"'s\",\n",
       " 27: 'not',\n",
       " 28: 'from',\n",
       " 29: 'there',\n",
       " 30: 'one',\n",
       " 31: 'up',\n",
       " 32: 'what',\n",
       " 33: 'him',\n",
       " 34: 'so',\n",
       " 35: 'bed',\n",
       " 36: 'now',\n",
       " 37: 'about',\n",
       " 38: 'no',\n",
       " 39: 'into',\n",
       " 40: 'by',\n",
       " 41: 'were',\n",
       " 42: 'out',\n",
       " 43: 'or',\n",
       " 44: 'harpooneer',\n",
       " 45: 'had',\n",
       " 46: 'then',\n",
       " 47: 'have',\n",
       " 48: 'an',\n",
       " 49: 'upon',\n",
       " 50: 'little',\n",
       " 51: 'some',\n",
       " 52: 'old',\n",
       " 53: 'like',\n",
       " 54: 'if',\n",
       " 55: 'they',\n",
       " 56: 'would',\n",
       " 57: 'do',\n",
       " 58: 'over',\n",
       " 59: 'landlord',\n",
       " 60: 'thought',\n",
       " 61: 'room',\n",
       " 62: 'when',\n",
       " 63: 'could',\n",
       " 64: \"n't\",\n",
       " 65: 'night',\n",
       " 66: 'here',\n",
       " 67: 'head',\n",
       " 68: 'such',\n",
       " 69: 'which',\n",
       " 70: 'man',\n",
       " 71: 'did',\n",
       " 72: 'sea',\n",
       " 73: 'time',\n",
       " 74: 'other',\n",
       " 75: 'very',\n",
       " 76: 'go',\n",
       " 77: 'these',\n",
       " 78: 'more',\n",
       " 79: 'though',\n",
       " 80: 'first',\n",
       " 81: 'sort',\n",
       " 82: 'said',\n",
       " 83: 'last',\n",
       " 84: 'down',\n",
       " 85: 'most',\n",
       " 86: 'been',\n",
       " 87: 'never',\n",
       " 88: 'your',\n",
       " 89: 'them',\n",
       " 90: 'must',\n",
       " 91: 'tell',\n",
       " 92: 'much',\n",
       " 93: 'good',\n",
       " 94: 'see',\n",
       " 95: 'off',\n",
       " 96: 'myself',\n",
       " 97: 'are',\n",
       " 98: 'yet',\n",
       " 99: 'sleep',\n",
       " 100: 'who',\n",
       " 101: 'seemed',\n",
       " 102: 'light',\n",
       " 103: 'way',\n",
       " 104: 'their',\n",
       " 105: 'just',\n",
       " 106: 'being',\n",
       " 107: 'than',\n",
       " 108: 'place',\n",
       " 109: 'queequeg',\n",
       " 110: 'great',\n",
       " 111: 'long',\n",
       " 112: 'before',\n",
       " 113: 'get',\n",
       " 114: 'round',\n",
       " 115: 'where',\n",
       " 116: 'still',\n",
       " 117: 'any',\n",
       " 118: 'too',\n",
       " 119: 'only',\n",
       " 120: 'door',\n",
       " 121: 'can',\n",
       " 122: 'himself',\n",
       " 123: 'heads',\n",
       " 124: 'come',\n",
       " 125: 'ever',\n",
       " 126: 'two',\n",
       " 127: 'enough',\n",
       " 128: 'made',\n",
       " 129: 'how',\n",
       " 130: 'hand',\n",
       " 131: 'same',\n",
       " 132: 'looking',\n",
       " 133: 'something',\n",
       " 134: 'may',\n",
       " 135: \"'\",\n",
       " 136: 'almost',\n",
       " 137: 'say',\n",
       " 138: 'should',\n",
       " 139: 'side',\n",
       " 140: 'why',\n",
       " 141: 'own',\n",
       " 142: 'we',\n",
       " 143: 'new',\n",
       " 144: 'again',\n",
       " 145: 'came',\n",
       " 146: 'arm',\n",
       " 147: 'house',\n",
       " 148: 'away',\n",
       " 149: 'might',\n",
       " 150: 'nothing',\n",
       " 151: 'take',\n",
       " 152: 'towards',\n",
       " 153: 'will',\n",
       " 154: 'under',\n",
       " 155: 'going',\n",
       " 156: 'make',\n",
       " 157: 'whale',\n",
       " 158: 'stood',\n",
       " 159: 'boots',\n",
       " 160: 'ye',\n",
       " 161: 'back',\n",
       " 162: \"'ll\",\n",
       " 163: 'tomahawk',\n",
       " 164: 'part',\n",
       " 165: 'world',\n",
       " 166: 'soon',\n",
       " 167: 'water',\n",
       " 168: 'against',\n",
       " 169: 'those',\n",
       " 170: 'between',\n",
       " 171: 'after',\n",
       " 172: 'whaling',\n",
       " 173: 'lay',\n",
       " 174: 'took',\n",
       " 175: 'half',\n",
       " 176: 'began',\n",
       " 177: 'face',\n",
       " 178: 'streets',\n",
       " 179: 'land',\n",
       " 180: 'better',\n",
       " 181: 'once',\n",
       " 182: 'voyage',\n",
       " 183: 'give',\n",
       " 184: 'rather',\n",
       " 185: 'well',\n",
       " 186: 'however',\n",
       " 187: 'else',\n",
       " 188: 'heard',\n",
       " 189: 'put',\n",
       " 190: 'stop',\n",
       " 191: 'dark',\n",
       " 192: 'went',\n",
       " 193: 'black',\n",
       " 194: 'window',\n",
       " 195: 'cannibal',\n",
       " 196: 'fire',\n",
       " 197: 'every',\n",
       " 198: 'ship',\n",
       " 199: 'stand',\n",
       " 200: 'strange',\n",
       " 201: 'without',\n",
       " 202: 'feet',\n",
       " 203: 'whether',\n",
       " 204: 'because',\n",
       " 205: 'eyes',\n",
       " 206: 'think',\n",
       " 207: 'thinks',\n",
       " 208: 'idea',\n",
       " 209: 'bag',\n",
       " 210: 'nantucket',\n",
       " 211: 'late',\n",
       " 212: 'cold',\n",
       " 213: 'our',\n",
       " 214: 'found',\n",
       " 215: 'full',\n",
       " 216: 'morning',\n",
       " 217: 'sleeping',\n",
       " 218: 'got',\n",
       " 219: 'mind',\n",
       " 220: 'her',\n",
       " 221: 'right',\n",
       " 222: 'its',\n",
       " 223: 'look',\n",
       " 224: 'town',\n",
       " 225: 'south',\n",
       " 226: 'does',\n",
       " 227: 'let',\n",
       " 228: 'set',\n",
       " 229: 'yourself',\n",
       " 230: 'image',\n",
       " 231: 'saw',\n",
       " 232: 'am',\n",
       " 233: 'besides',\n",
       " 234: 'sailor',\n",
       " 235: 'seas',\n",
       " 236: 'rolled',\n",
       " 237: 'till',\n",
       " 238: 'day',\n",
       " 239: 'sign',\n",
       " 240: 'looked',\n",
       " 241: 'hard',\n",
       " 242: 'moment',\n",
       " 243: 'corner',\n",
       " 244: 'entry',\n",
       " 245: 'four',\n",
       " 246: 'wall',\n",
       " 247: 'savage',\n",
       " 248: 'table',\n",
       " 249: 'indeed',\n",
       " 250: 'bench',\n",
       " 251: 'chest',\n",
       " 252: 'while',\n",
       " 253: 'stranger',\n",
       " 254: 'possible',\n",
       " 255: 'feeling',\n",
       " 256: 'floor',\n",
       " 257: 'squares',\n",
       " 258: 'hat',\n",
       " 259: 'particular',\n",
       " 260: 'having',\n",
       " 261: 'years',\n",
       " 262: 'harpoon',\n",
       " 263: 'ishmael',\n",
       " 264: 'whenever',\n",
       " 265: 'mouth',\n",
       " 266: 'high',\n",
       " 267: 'knew',\n",
       " 268: 'men',\n",
       " 269: 'hours',\n",
       " 270: 'green',\n",
       " 271: 'bit',\n",
       " 272: 'within',\n",
       " 273: 'picture',\n",
       " 274: 'told',\n",
       " 275: 'story',\n",
       " 276: 'mean',\n",
       " 277: 'speak',\n",
       " 278: 'order',\n",
       " 279: 'making',\n",
       " 280: 'even',\n",
       " 281: 'perhaps',\n",
       " 282: 'things',\n",
       " 283: 'answer',\n",
       " 284: 'parts',\n",
       " 285: 'wild',\n",
       " 286: 'reason',\n",
       " 287: 'young',\n",
       " 288: 'craft',\n",
       " 289: 'business',\n",
       " 290: 'dead',\n",
       " 291: 'another',\n",
       " 292: 'middle',\n",
       " 293: 'sure',\n",
       " 294: 'candle',\n",
       " 295: 'presently',\n",
       " 296: 'low',\n",
       " 297: 'turned',\n",
       " 298: 'teeth',\n",
       " 299: 'dim',\n",
       " 300: 'euroclydon',\n",
       " 301: 'kept',\n",
       " 302: 'glass',\n",
       " 303: 'afterwards',\n",
       " 304: 'large',\n",
       " 305: 'three',\n",
       " 306: 'telling',\n",
       " 307: 'getting',\n",
       " 308: 'small',\n",
       " 309: 'next',\n",
       " 310: 'seeing',\n",
       " 311: 'sell',\n",
       " 312: 'felt',\n",
       " 313: 'sun',\n",
       " 314: 'money',\n",
       " 315: 'sail',\n",
       " 316: 'coffin',\n",
       " 317: 'especially',\n",
       " 318: 'street',\n",
       " 319: 'city',\n",
       " 320: 'few',\n",
       " 321: 'previous',\n",
       " 322: 'sight',\n",
       " 323: 'days',\n",
       " 324: 'straight',\n",
       " 325: 'nigh',\n",
       " 326: 'legs',\n",
       " 327: 'try',\n",
       " 328: 'yes',\n",
       " 329: 'unless',\n",
       " 330: 'poor',\n",
       " 331: 'coat',\n",
       " 332: 'passenger',\n",
       " 333: 'taking',\n",
       " 334: 'true',\n",
       " 335: 'thing',\n",
       " 336: 'ai',\n",
       " 337: 'always',\n",
       " 338: 'us',\n",
       " 339: 'really',\n",
       " 340: 'marvellous',\n",
       " 341: 'heaven',\n",
       " 342: 'air',\n",
       " 343: 'far',\n",
       " 344: 'second',\n",
       " 345: 'many',\n",
       " 346: 'has',\n",
       " 347: 'unaccountable',\n",
       " 348: 'grand',\n",
       " 349: 'jolly',\n",
       " 350: 'open',\n",
       " 351: 'shirt',\n",
       " 352: 'cape',\n",
       " 353: 'bedford',\n",
       " 354: 'fine',\n",
       " 355: 'further',\n",
       " 356: 'ice',\n",
       " 357: 'frost',\n",
       " 358: 'foot',\n",
       " 359: 'wide',\n",
       " 360: 'white',\n",
       " 361: 'tall',\n",
       " 362: 'i.',\n",
       " 363: 'wooden',\n",
       " 364: 'worse',\n",
       " 365: 'death',\n",
       " 366: 'mine',\n",
       " 367: 'lazarus',\n",
       " 368: 'keep',\n",
       " 369: 'along',\n",
       " 370: 'hung',\n",
       " 371: 'throwing',\n",
       " 372: 'centre',\n",
       " 373: 'rest',\n",
       " 374: 'fact',\n",
       " 375: 'hair',\n",
       " 376: 'broken',\n",
       " 377: 'kill',\n",
       " 378: 'through',\n",
       " 379: 'chimney',\n",
       " 380: 'fancy',\n",
       " 381: 'bar',\n",
       " 382: 'trying',\n",
       " 383: 'dumplings',\n",
       " 384: 'heavens',\n",
       " 385: 'manner',\n",
       " 386: 'devil',\n",
       " 387: 'together',\n",
       " 388: 'seen',\n",
       " 389: 'deal',\n",
       " 390: 'know',\n",
       " 391: 'skin',\n",
       " 392: 'ca',\n",
       " 393: 'shavings',\n",
       " 394: 'peddling',\n",
       " 395: 'sunday',\n",
       " 396: 'counterpane',\n",
       " 397: 'mat',\n",
       " 398: 'christian',\n",
       " 399: 'commenced',\n",
       " 400: 'thinking',\n",
       " 401: 'similar',\n",
       " 402: 'afraid',\n",
       " 403: 'length',\n",
       " 404: 'idol',\n",
       " 405: 'e',\n",
       " 406: 'sabbee',\n",
       " 407: 'waking',\n",
       " 408: 'ago',\n",
       " 409: 'find',\n",
       " 410: 'damp',\n",
       " 411: 'soul',\n",
       " 412: 'strong',\n",
       " 413: 'account',\n",
       " 414: 'sword',\n",
       " 415: 'quietly',\n",
       " 416: 'degree',\n",
       " 417: 'left',\n",
       " 418: 'around',\n",
       " 419: 'fixed',\n",
       " 420: 'ships',\n",
       " 421: 'miles',\n",
       " 422: 'country',\n",
       " 423: 'stream',\n",
       " 424: 'lead',\n",
       " 425: 'american',\n",
       " 426: 'artist',\n",
       " 427: 'each',\n",
       " 428: 'goes',\n",
       " 429: 'deep',\n",
       " 430: 'distant',\n",
       " 431: 'winds',\n",
       " 432: 'blue',\n",
       " 433: 'among',\n",
       " 434: 'suddenly',\n",
       " 435: 'feel',\n",
       " 436: 'meaning',\n",
       " 437: 'phantom',\n",
       " 438: 'life',\n",
       " 439: 'passengers',\n",
       " 440: 'nor',\n",
       " 441: 'kind',\n",
       " 442: 'quite',\n",
       " 443: 'care',\n",
       " 444: 'board',\n",
       " 445: 'somehow',\n",
       " 446: 'broiled',\n",
       " 447: 'mast',\n",
       " 448: 'sense',\n",
       " 449: 'knowing',\n",
       " 450: 'either',\n",
       " 451: 'passed',\n",
       " 452: 'hands',\n",
       " 453: 'paying',\n",
       " 454: 'pay',\n",
       " 455: 'penny',\n",
       " 456: 'sailors',\n",
       " 457: 'exactly',\n",
       " 458: 'short',\n",
       " 459: 'easy',\n",
       " 460: 'portentous',\n",
       " 461: 'island',\n",
       " 462: 'nameless',\n",
       " 463: 'sounds',\n",
       " 464: 'since',\n",
       " 465: 'snow',\n",
       " 466: 'saturday',\n",
       " 467: 'matter',\n",
       " 468: 'red',\n",
       " 469: 'partly',\n",
       " 470: 'ere',\n",
       " 471: 'became',\n",
       " 472: 'meanwhile',\n",
       " 473: 'pocket',\n",
       " 474: 'darkness',\n",
       " 475: 'fish',\n",
       " 476: 'inn',\n",
       " 477: 'watch',\n",
       " 478: 'broad',\n",
       " 479: 'entering',\n",
       " 480: 'ha',\n",
       " 481: 'ashes',\n",
       " 482: 'opened',\n",
       " 483: 'spouter',\n",
       " 484: 'name',\n",
       " 485: 'suppose',\n",
       " 486: 'quiet',\n",
       " 487: 'best',\n",
       " 488: 'tempestuous',\n",
       " 489: 'says',\n",
       " 490: 'thou',\n",
       " 491: 'both',\n",
       " 492: 'occurred',\n",
       " 493: 'dives',\n",
       " 494: 'holding',\n",
       " 495: 'frozen',\n",
       " 496: 'altogether',\n",
       " 497: 'plain',\n",
       " 498: 'whom',\n",
       " 499: 'clean',\n",
       " 500: 'human',\n",
       " 501: 'entered',\n",
       " 502: 'wrinkled',\n",
       " 503: 'shelf',\n",
       " 504: 'jonah',\n",
       " 505: 'blanket',\n",
       " 506: \"goin'\",\n",
       " 507: 'bitter',\n",
       " 508: 'supper',\n",
       " 509: 'sat',\n",
       " 510: 'settle',\n",
       " 511: 'chap',\n",
       " 512: 'help',\n",
       " 513: 'spend',\n",
       " 514: 'landed',\n",
       " 515: 'standing',\n",
       " 516: 'held',\n",
       " 517: 'somewhat',\n",
       " 518: 'sober',\n",
       " 519: 'whole',\n",
       " 520: 'dam',\n",
       " 521: 'brown',\n",
       " 522: 'bulkington',\n",
       " 523: \"o'clock\",\n",
       " 524: 'none',\n",
       " 525: 'coming',\n",
       " 526: \"'ve\",\n",
       " 527: 'wait',\n",
       " 528: 'plane',\n",
       " 529: 'saying',\n",
       " 530: 'grinning',\n",
       " 531: 'placed',\n",
       " 532: 'shouted',\n",
       " 533: 'bedfellow',\n",
       " 534: 'zealand',\n",
       " 535: 'sal',\n",
       " 536: 'wash',\n",
       " 537: 'thrown',\n",
       " 538: 'purplish',\n",
       " 539: 'turn',\n",
       " 540: 'completely',\n",
       " 541: 'fear',\n",
       " 542: 'grego',\n",
       " 543: 'baby',\n",
       " 544: 'slowly',\n",
       " 545: 'civilized',\n",
       " 546: 'purse',\n",
       " 547: 'monkey',\n",
       " 548: 'involuntarily',\n",
       " 549: 'pausing',\n",
       " 550: 'warehouses',\n",
       " 551: 'requires',\n",
       " 552: 'people',\n",
       " 553: 'nearly',\n",
       " 554: 'ocean',\n",
       " 555: 'indian',\n",
       " 556: 'waterward',\n",
       " 557: 'battery',\n",
       " 558: 'noble',\n",
       " 559: 'washed',\n",
       " 560: 'crowds',\n",
       " 561: 'sabbath',\n",
       " 562: 'afternoon',\n",
       " 563: 'thence',\n",
       " 564: 'silent',\n",
       " 565: 'thousands',\n",
       " 566: 'reveries',\n",
       " 567: 'leaning',\n",
       " 568: 'seated',\n",
       " 569: 'bulwarks',\n",
       " 570: 'aloft',\n",
       " 571: 'week',\n",
       " 572: 'plaster',\n",
       " 573: 'gone',\n",
       " 574: 'bound',\n",
       " 575: 'content',\n",
       " 576: 'yonder',\n",
       " 577: 'falling',\n",
       " 578: 'north',\n",
       " 579: 'please',\n",
       " 580: 'ten',\n",
       " 581: 'leaves',\n",
       " 582: 'magic',\n",
       " 583: 'plunged',\n",
       " 584: 'metaphysical',\n",
       " 585: 'chief',\n",
       " 586: 'trunk',\n",
       " 587: 'meadow',\n",
       " 588: 'smoke',\n",
       " 589: 'reaching',\n",
       " 590: 'hill',\n",
       " 591: 'thus',\n",
       " 592: 'pine',\n",
       " 593: 'sighs',\n",
       " 594: 'shepherd',\n",
       " 595: 'june',\n",
       " 596: 'scores',\n",
       " 597: 'thousand',\n",
       " 598: 'sadly',\n",
       " 599: 'robust',\n",
       " 600: 'healthy',\n",
       " 601: 'boy',\n",
       " 602: 'crazy',\n",
       " 603: 'hold',\n",
       " 604: 'holy',\n",
       " 605: 'brother',\n",
       " 606: 'ourselves',\n",
       " 607: 'begin',\n",
       " 608: 'grow',\n",
       " 609: 'inferred',\n",
       " 610: 'needs',\n",
       " 611: \"don't\",\n",
       " 612: 'themselves',\n",
       " 613: 'commodore',\n",
       " 614: 'captain',\n",
       " 615: 'cook',\n",
       " 616: 'glory',\n",
       " 617: 'whatsoever',\n",
       " 618: 'confess',\n",
       " 619: 'officer',\n",
       " 620: 'respectfully',\n",
       " 621: 'horse',\n",
       " 622: 'huge',\n",
       " 623: 'houses',\n",
       " 624: 'forecastle',\n",
       " 625: 'jump',\n",
       " 626: 'spar',\n",
       " 627: 'particularly',\n",
       " 628: 'putting',\n",
       " 629: 'tar',\n",
       " 630: 'schoolmaster',\n",
       " 631: 'boys',\n",
       " 632: 'transition',\n",
       " 633: 'grin',\n",
       " 634: 'bear',\n",
       " 635: 'hunks',\n",
       " 636: 'sweep',\n",
       " 637: 'weighed',\n",
       " 638: 'anything',\n",
       " 639: 'less',\n",
       " 640: 'thump',\n",
       " 641: 'point',\n",
       " 642: 'view',\n",
       " 643: 'single',\n",
       " 644: 'difference',\n",
       " 645: 'act',\n",
       " 646: 'uncomfortable',\n",
       " 647: 'compare',\n",
       " 648: 'earthly',\n",
       " 649: 'enter',\n",
       " 650: 'deck',\n",
       " 651: 'quarter',\n",
       " 652: 'leaders',\n",
       " 653: 'smelt',\n",
       " 654: 'fates',\n",
       " 655: 'doubtless',\n",
       " 656: 'formed',\n",
       " 657: 'run',\n",
       " 658: 'stage',\n",
       " 659: 'shabby',\n",
       " 660: 'others',\n",
       " 661: 'circumstances',\n",
       " 662: 'motives',\n",
       " 663: 'various',\n",
       " 664: 'mysterious',\n",
       " 665: 'curiosity',\n",
       " 666: 'tormented',\n",
       " 667: 'everlasting',\n",
       " 668: 'wonder',\n",
       " 669: 'purpose',\n",
       " 670: 'floated',\n",
       " 671: 'stuffed',\n",
       " 672: 'horn',\n",
       " 673: 'arrived',\n",
       " 674: 'offer',\n",
       " 675: 'following',\n",
       " 676: 'embark',\n",
       " 677: 'pleased',\n",
       " 678: 'original',\n",
       " 679: 'stranded',\n",
       " 680: 'leviathan',\n",
       " 681: 'whales',\n",
       " 682: 'nay',\n",
       " 683: 'dismal',\n",
       " 684: 'wherever',\n",
       " 685: 'dreary',\n",
       " 686: 'crossed',\n",
       " 687: 'expensive',\n",
       " 688: 'bright',\n",
       " 689: 'windows',\n",
       " 690: 'packed',\n",
       " 691: 'inches',\n",
       " 692: 'thick',\n",
       " 693: 'hear',\n",
       " 694: 'tinkling',\n",
       " 695: 'glasses',\n",
       " 696: 'blackness',\n",
       " 697: 'moving',\n",
       " 698: 'hour',\n",
       " 699: 'proved',\n",
       " 700: 'meant',\n",
       " 701: 'public',\n",
       " 702: 'box',\n",
       " 703: 'flying',\n",
       " 704: 'harpoons',\n",
       " 705: 'trap',\n",
       " 706: 'loud',\n",
       " 707: 'voice',\n",
       " 708: 'sitting',\n",
       " 709: 'beyond',\n",
       " 710: 'negro',\n",
       " 711: 'creaking',\n",
       " 712: 'swinging',\n",
       " 713: 'painting',\n",
       " 714: 'representing',\n",
       " 715: 'connexion',\n",
       " 716: 'peter',\n",
       " 717: 'itself',\n",
       " 718: 'carted',\n",
       " 719: 'burnt',\n",
       " 720: 'spot',\n",
       " 721: 'queer',\n",
       " 722: 'gable',\n",
       " 723: 'ended',\n",
       " 724: 'sharp',\n",
       " 725: 'wind',\n",
       " 726: 'howling',\n",
       " 727: 'nevertheless',\n",
       " 728: 'called',\n",
       " 729: 'outside',\n",
       " 730: 'passage',\n",
       " 731: 'body',\n",
       " 732: 'curbstone',\n",
       " 733: 'corn',\n",
       " 734: 'pooh',\n",
       " 735: 'northern',\n",
       " 736: 'lights',\n",
       " 737: 'summer',\n",
       " 738: 'lengthwise',\n",
       " 739: 'gods',\n",
       " 740: 'lie',\n",
       " 741: 'plenty',\n",
       " 742: 'study',\n",
       " 743: 'series',\n",
       " 744: 'arrive',\n",
       " 745: 'shadows',\n",
       " 746: 'dint',\n",
       " 747: 'conclusion',\n",
       " 748: 'confounded',\n",
       " 749: 'limber',\n",
       " 750: 'truly',\n",
       " 751: 'drive',\n",
       " 752: 'unimaginable',\n",
       " 753: 'midnight',\n",
       " 754: 'unnatural',\n",
       " 755: 'breaking',\n",
       " 756: 'design',\n",
       " 757: 'opposite',\n",
       " 758: 'monstrous',\n",
       " 759: 'knots',\n",
       " 760: 'vast',\n",
       " 761: 'handle',\n",
       " 762: 'wondered',\n",
       " 763: 'mixed',\n",
       " 764: 'deformed',\n",
       " 765: 'flung',\n",
       " 766: 'iron',\n",
       " 767: 'arched',\n",
       " 768: 'cut',\n",
       " 769: 'times',\n",
       " 770: 'beneath',\n",
       " 771: 'covered',\n",
       " 772: 'gathered',\n",
       " 773: 'stands',\n",
       " 774: 'rude',\n",
       " 775: 'bone',\n",
       " 776: 'abominable',\n",
       " 777: 'measure',\n",
       " 778: 'seamen',\n",
       " 779: 'skrimshander',\n",
       " 780: 'sought',\n",
       " 781: 'added',\n",
       " 782: 'forehead',\n",
       " 783: 'objections',\n",
       " 784: \"'d\",\n",
       " 785: 'used',\n",
       " 786: 'depend',\n",
       " 787: 'decent',\n",
       " 788: 'want',\n",
       " 789: 'ready',\n",
       " 790: 'working',\n",
       " 791: 'space',\n",
       " 792: 'lips',\n",
       " 793: 'fingers',\n",
       " 794: 'fare',\n",
       " 795: 'fellow',\n",
       " 796: 'nightmare',\n",
       " 797: 'nt',\n",
       " 798: 'complexioned',\n",
       " 799: 'eats',\n",
       " 800: \"'em\",\n",
       " 801: 'afore',\n",
       " 802: 'resolved',\n",
       " 803: 'noise',\n",
       " 804: 'offing',\n",
       " 805: 'shaggy',\n",
       " 806: 'woollen',\n",
       " 807: 'stiff',\n",
       " 808: 'labrador',\n",
       " 809: 'wake',\n",
       " 810: 'bad',\n",
       " 811: 'mounted',\n",
       " 812: 'generally',\n",
       " 813: 'shipmates',\n",
       " 814: 'become',\n",
       " 815: 'height',\n",
       " 816: 'seem',\n",
       " 817: 'plan',\n",
       " 818: 'private',\n",
       " 819: 'unknown',\n",
       " 820: 'apartment',\n",
       " 821: 'hammock',\n",
       " 822: 'linen',\n",
       " 823: 'home',\n",
       " 824: 'hole',\n",
       " 825: 'mattress',\n",
       " 826: 'planing',\n",
       " 827: 'knot',\n",
       " 828: 'near',\n",
       " 829: 'sake',\n",
       " 830: 'chair',\n",
       " 831: 'narrow',\n",
       " 832: 'leaving',\n",
       " 833: 'interval',\n",
       " 834: 'met',\n",
       " 835: 'inside',\n",
       " 836: 'violent',\n",
       " 837: 'ones',\n",
       " 838: 'comprehension',\n",
       " 839: 'bird',\n",
       " 840: 'airley',\n",
       " 841: 'airth',\n",
       " 842: 'engaged',\n",
       " 843: 'whittling',\n",
       " 844: 'guess',\n",
       " 845: 'done',\n",
       " 846: 'break',\n",
       " 847: 'broke',\n",
       " 848: 'understand',\n",
       " 849: 'certain',\n",
       " 850: 'demand',\n",
       " 851: 'selling',\n",
       " 852: 'sir',\n",
       " 853: 'string',\n",
       " 854: 'mystery',\n",
       " 855: 'showed',\n",
       " 856: 'dangerous',\n",
       " 857: 'flukes',\n",
       " 858: 'slept',\n",
       " 859: 'big',\n",
       " 860: 'sam',\n",
       " 861: 'lighted',\n",
       " 862: 'wo',\n",
       " 863: 'stairs',\n",
       " 864: 'placing',\n",
       " 865: 'double',\n",
       " 866: 'eyeing',\n",
       " 867: 'belonging',\n",
       " 868: 'papered',\n",
       " 869: 'parcel',\n",
       " 870: 'tried',\n",
       " 871: 'satisfactory',\n",
       " 872: 'concerning',\n",
       " 873: 'edges',\n",
       " 874: 'stuck',\n",
       " 875: 'gave',\n",
       " 876: 'neck',\n",
       " 877: 'sleeves',\n",
       " 878: 'undressed',\n",
       " 879: 'remembering',\n",
       " 880: 'jumped',\n",
       " 881: 'pantaloons',\n",
       " 882: 'blowing',\n",
       " 883: 'doze',\n",
       " 884: 'pretty',\n",
       " 885: 'heavy',\n",
       " 886: 'save',\n",
       " 887: 'infernal',\n",
       " 888: 'peddler',\n",
       " 889: 'yellow',\n",
       " 890: 'colour',\n",
       " 891: 'dreadfully',\n",
       " 892: 'sticking',\n",
       " 893: 'cheeks',\n",
       " 894: 'truth',\n",
       " 895: 'remembered',\n",
       " 896: 'whaleman',\n",
       " 897: 'tattooed',\n",
       " 898: 'concluded',\n",
       " 899: 'lying',\n",
       " 900: 'tanning',\n",
       " 901: 'hot',\n",
       " 902: 'produced',\n",
       " 903: 'beaver',\n",
       " 904: 'singing',\n",
       " 905: 'bolted',\n",
       " 906: 'arms',\n",
       " 907: 'running',\n",
       " 908: 'curious',\n",
       " 909: 'hunch',\n",
       " 910: 'congo',\n",
       " 911: 'ill',\n",
       " 912: 'takes',\n",
       " 913: 'biscuit',\n",
       " 914: 'top',\n",
       " 915: 'lamp',\n",
       " 916: 'succeeded',\n",
       " 917: 'polite',\n",
       " 918: 'guttural',\n",
       " 919: 'pagan',\n",
       " 920: 'spell',\n",
       " 921: 'tobacco',\n",
       " 922: 'grunt',\n",
       " 923: 'whatever',\n",
       " 924: 'ee',\n",
       " 925: 'horrid',\n",
       " 926: 'pipe',\n",
       " 927: 'smoking',\n",
       " 928: 'complied',\n",
       " 929: 'patchwork',\n",
       " 930: 'figure',\n",
       " 931: 'shade',\n",
       " 932: 'quilt',\n",
       " 933: 'hugging',\n",
       " 934: 'sensations',\n",
       " 935: 'explain',\n",
       " 936: 'remember',\n",
       " 937: 'circumstance',\n",
       " 938: 'reality',\n",
       " 939: 'stepmother',\n",
       " 940: 'sixteen',\n",
       " 941: 'abed',\n",
       " 942: 'troubled',\n",
       " 943: 'supernatural',\n",
       " 944: 'ages',\n",
       " 945: 'awful',\n",
       " 946: 'consciousness',\n",
       " 947: 'observing',\n",
       " 948: 'creature',\n",
       " 949: 'dress',\n",
       " 950: 'watching',\n",
       " 951: 'probably',\n",
       " 952: 'toilet',\n",
       " 953: 'wrapped',\n",
       " 954: 'precisely',\n",
       " 955: 'jacket',\n",
       " 956: 'call',\n",
       " 957: 'shore',\n",
       " 958: 'watery',\n",
       " 959: 'driving',\n",
       " 960: 'spleen',\n",
       " 961: 'regulating',\n",
       " 962: 'circulation',\n",
       " 963: 'growing',\n",
       " 964: 'grim',\n",
       " 965: 'drizzly',\n",
       " 966: 'november',\n",
       " 967: 'bringing',\n",
       " 968: 'rear',\n",
       " 969: 'funeral',\n",
       " 970: 'meet',\n",
       " 971: 'hypos',\n",
       " 972: 'upper',\n",
       " 973: 'moral',\n",
       " 974: 'principle',\n",
       " 975: 'prevent',\n",
       " 976: 'deliberately',\n",
       " 977: 'stepping',\n",
       " 978: 'methodically',\n",
       " 979: 'knocking',\n",
       " 980: 'hats',\n",
       " 981: 'substitute',\n",
       " 982: 'pistol',\n",
       " 983: 'ball',\n",
       " 984: 'philosophical',\n",
       " 985: 'flourish',\n",
       " 986: 'cato',\n",
       " 987: 'throws',\n",
       " 988: 'surprising',\n",
       " 989: 'cherish',\n",
       " 990: 'feelings',\n",
       " 991: 'insular',\n",
       " 992: 'manhattoes',\n",
       " 993: 'belted',\n",
       " 994: 'wharves',\n",
       " 995: 'isles',\n",
       " 996: 'coral',\n",
       " 997: 'reefs',\n",
       " 998: 'commerce',\n",
       " 999: 'surrounds',\n",
       " 1000: 'surf',\n",
       " ...}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90198438",
   "metadata": {},
   "source": [
    "## No of unique word in this 4 chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "edf47299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:42.610778Z",
     "start_time": "2022-06-27T14:01:42.605785Z"
    }
   },
   "outputs": [],
   "source": [
    "no_of_vocab=len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7fa6f",
   "metadata": {},
   "source": [
    "## So our new data will be this after casting to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f95eb89f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:01.965250Z",
     "start_time": "2022-06-27T14:37:01.935116Z"
    }
   },
   "outputs": [],
   "source": [
    "NewSentences=np.array(NewSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "77585792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:02.938480Z",
     "start_time": "2022-06-27T14:37:02.924477Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 956,   14,  263, ..., 2713,   14,   24],\n",
       "       [  14,  263,   51, ...,   14,   24,  957],\n",
       "       [ 263,   51,  261, ...,   24,  957,    5],\n",
       "       ...,\n",
       "       [ 952,   12,  166, ...,  262,   53,    2],\n",
       "       [  12,  166, 2712, ...,   53,    2, 2718],\n",
       "       [ 166, 2712,    3, ...,    2, 2718,   26]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewSentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63cd44",
   "metadata": {},
   "source": [
    "## So first 25 will be the input and the last word will be the output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cbfa45",
   "metadata": {},
   "source": [
    "### Our input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2a61bd3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:08.628112Z",
     "start_time": "2022-06-27T14:37:08.623124Z"
    }
   },
   "outputs": [],
   "source": [
    "X=NewSentences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6f5da21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:09.738960Z",
     "start_time": "2022-06-27T14:37:09.717943Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 956,   14,  263, ...,    6, 2713,   14],\n",
       "       [  14,  263,   51, ..., 2713,   14,   24],\n",
       "       [ 263,   51,  261, ...,   14,   24,  957],\n",
       "       ...,\n",
       "       [ 952,   12,  166, ...,   11,  262,   53],\n",
       "       [  12,  166, 2712, ...,  262,   53,    2],\n",
       "       [ 166, 2712,    3, ...,   53,    2, 2718]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bb6d1e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:39.984623Z",
     "start_time": "2022-06-27T14:37:39.972655Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11312, 25)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39989c04",
   "metadata": {},
   "source": [
    "### our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "9f6ef6e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T15:36:37.630557Z",
     "start_time": "2022-06-27T15:36:37.619586Z"
    }
   },
   "outputs": [],
   "source": [
    "y=NewSentences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4a3066b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T15:36:38.556787Z",
     "start_time": "2022-06-27T15:36:38.547828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  24,  957,    5, ...,    2, 2718,   26])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "50d907b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T15:36:40.452650Z",
     "start_time": "2022-06-27T15:36:40.434654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11312,)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca7d76",
   "metadata": {},
   "source": [
    "### Now we need to convert our output to categories to (one hot encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "82166e5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T15:36:42.613562Z",
     "start_time": "2022-06-27T15:36:42.605559Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "db59b5f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T15:36:43.863117Z",
     "start_time": "2022-06-27T15:36:43.835191Z"
    }
   },
   "outputs": [],
   "source": [
    "y=to_categorical(y,num_classes=no_of_vocab+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "3012c893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T15:36:44.691916Z",
     "start_time": "2022-06-27T15:36:44.679047Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2582471",
   "metadata": {},
   "source": [
    "### The length of the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b03f0988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:46.819074Z",
     "start_time": "2022-06-27T14:37:46.812092Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_len=X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "719d4682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:47.728472Z",
     "start_time": "2022-06-27T14:37:47.721448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b72d37",
   "metadata": {},
   "source": [
    "# Now the time to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7df6a266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:03.920254Z",
     "start_time": "2022-06-27T14:01:03.911235Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "21aec1f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:05.139419Z",
     "start_time": "2022-06-27T14:01:05.006416Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Dropout,Embedding\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "301a1eab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:01:12.875367Z",
     "start_time": "2022-06-27T14:01:12.863399Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size,seq_len):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocabulary_size,seq_len,input_length=seq_len))\n",
    "    model.add(LSTM(150,return_sequences=True))\n",
    "    model.add(LSTM(150))\n",
    "    model.add(Dense(150,activation='relu'))\n",
    "    model.add(Dense(vocabulary_size,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8a1a6242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:50.364095Z",
     "start_time": "2022-06-27T14:37:49.886901Z"
    }
   },
   "outputs": [],
   "source": [
    "model=create_model(no_of_vocab+1,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "82abb921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:51.509631Z",
     "start_time": "2022-06-27T14:37:51.486650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 25, 25)            67975     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 25, 150)           105600    \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 150)               180600    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 150)               22650     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2719)              410569    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 787,394\n",
      "Trainable params: 787,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ef8ad6fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:37:54.473327Z",
     "start_time": "2022-06-27T14:37:54.453345Z"
    }
   },
   "outputs": [],
   "source": [
    "from pickle import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1b39bc3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T02:33:20.870851Z",
     "start_time": "2022-06-27T02:30:26.179840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "89/89 [==============================] - 8s 89ms/step - loss: 4.5142 - accuracy: 0.1086\n",
      "Epoch 2/20\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 4.4701 - accuracy: 0.1073\n",
      "Epoch 3/20\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 4.4678 - accuracy: 0.1050\n",
      "Epoch 4/20\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 4.4145 - accuracy: 0.1109\n",
      "Epoch 5/20\n",
      "89/89 [==============================] - 9s 104ms/step - loss: 4.3680 - accuracy: 0.1139\n",
      "Epoch 6/20\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 4.3183 - accuracy: 0.1132\n",
      "Epoch 7/20\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 4.2715 - accuracy: 0.1150\n",
      "Epoch 8/20\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 4.2241 - accuracy: 0.1158\n",
      "Epoch 9/20\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 4.1830 - accuracy: 0.1196\n",
      "Epoch 10/20\n",
      "89/89 [==============================] - 9s 105ms/step - loss: 4.1466 - accuracy: 0.1217\n",
      "Epoch 11/20\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 4.1013 - accuracy: 0.1266\n",
      "Epoch 12/20\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 4.0514 - accuracy: 0.1283\n",
      "Epoch 13/20\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 4.0089 - accuracy: 0.1300\n",
      "Epoch 14/20\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 3.9991 - accuracy: 0.1375\n",
      "Epoch 15/20\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 3.9548 - accuracy: 0.1400\n",
      "Epoch 16/20\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 3.9383 - accuracy: 0.1422\n",
      "Epoch 17/20\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 3.9300 - accuracy: 0.1470\n",
      "Epoch 18/20\n",
      "89/89 [==============================] - 9s 98ms/step - loss: 3.8940 - accuracy: 0.1513\n",
      "Epoch 19/20\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 4.1770 - accuracy: 0.1345\n",
      "Epoch 20/20\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 3.9572 - accuracy: 0.1520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a7dcc6a820>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,batch_size=128,epochs=20,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6ef92028",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T02:41:59.026190Z",
     "start_time": "2022-06-27T02:41:57.559946Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"lastversion.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a08fea15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T02:43:06.773969Z",
     "start_time": "2022-06-27T02:43:05.734276Z"
    }
   },
   "outputs": [],
   "source": [
    "dump(tokenizer, open('epochBIG', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ea931",
   "metadata": {},
   "source": [
    "## I Trained The model on GoogleColab for 300 Epoches and get about 0.99% accuracy so will use this model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "b1a6fd3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:39:20.665946Z",
     "start_time": "2022-06-27T14:39:20.089277Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "TrainedModel=keras.models.load_model(\"lastversion.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "503d4a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:39:22.088908Z",
     "start_time": "2022-06-27T14:39:22.070956Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer=load(open(\"epochBIG\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d8bed",
   "metadata": {},
   "source": [
    "## Now Testing Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "51c3bf70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:43:12.030465Z",
     "start_time": "2022-06-27T14:43:12.023227Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    \n",
    "    # Final Output\n",
    "    output_text = []\n",
    "    \n",
    "    # Intial Seed Sequence\n",
    "    input_text = seed_text\n",
    "    \n",
    "    # Create num_gen_words\n",
    "    for i in range(num_gen_words):\n",
    "        \n",
    "        # Take the input text string and encode it to a sequence\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        # Pad sequences to our trained rate (50 words in the video)\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        \n",
    "        # Predict Class Probabilities for each word\n",
    "        pred_word_ind =  model.predict(pad_encoded,verbose=0)[0].argmax()\n",
    "        \n",
    "        # Grab word\n",
    "        pred_word = tokenizer.index_word[pred_word_ind] \n",
    "        \n",
    "        # Update the sequence of input text (shifting one over with the new word)\n",
    "        input_text += ' ' + pred_word\n",
    "        \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    # Make it look like a sentence.\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39520a",
   "metadata": {},
   "source": [
    "### Grab a random seed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "48100cf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T15:51:24.942813Z",
     "start_time": "2022-06-27T15:51:24.927852Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(101)\n",
    "random_pick = random.randint(0,len(text_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "724e4b52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T15:51:25.719758Z",
     "start_time": "2022-06-27T15:51:25.711761Z"
    }
   },
   "outputs": [],
   "source": [
    "random_seed_text = Sentences[random_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "7e80dfd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T15:51:26.360364Z",
     "start_time": "2022-06-27T15:51:26.348397Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thought',\n",
       " 'i',\n",
       " 'to',\n",
       " 'myself',\n",
       " 'the',\n",
       " 'man',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'human',\n",
       " 'being',\n",
       " 'just',\n",
       " 'as',\n",
       " 'i',\n",
       " 'am',\n",
       " 'he',\n",
       " 'has',\n",
       " 'just',\n",
       " 'as',\n",
       " 'much',\n",
       " 'reason',\n",
       " 'to',\n",
       " 'fear',\n",
       " 'me',\n",
       " 'as',\n",
       " 'i',\n",
       " 'have']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "8c840ec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T15:51:31.580771Z",
     "start_time": "2022-06-27T15:51:29.723041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"to be afraid of him better sleep with a sober cannibal than a drunken christian landlord said i tell him to stash his tomahawk there or pipe or whatever you call it tell him to stop smoking in short and i will turn in with him but i do n't\""
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(TrainedModel,tokenizer,seq_len,seed_text=seed_text,num_gen_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c5ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
